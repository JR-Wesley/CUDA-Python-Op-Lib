# ğŸš€ CUDA Ops Templateï¼šPyTorch è‡ªå®šä¹‰ CUDA ç®—å­å¼€å‘æ¨¡æ¿

ä¸€ä¸ªç®€æ´ã€å¯æ‰©å±•ã€å¼€ç®±å³ç”¨çš„ PyTorch CUDA æ‰©å±•å¼€å‘æ¨¡æ¿ï¼Œä¸“ä¸ºé«˜æ•ˆå¼€å‘å¤šä¸ªè‡ªå®šä¹‰ç®—å­ï¼ˆå¦‚ `matmul`ã€`bitonic_sort`ã€`MoE` ç­‰ï¼‰è€Œè®¾è®¡ã€‚

- âœ… æ”¯æŒ **å¼€å‘æœŸå³æ—¶ç¼–è¯‘**ï¼ˆæ— éœ€å®‰è£…ï¼‰
- âœ… æ”¯æŒ **å‘å¸ƒæœŸ pip å®‰è£…**ï¼ˆä¾¿äºé›†æˆï¼‰
- âœ… æ”¯æŒå¢åŠ  **è‡ªå®šä¹‰ç®—å­**
- âœ… ä½¿ç”¨ `LibTorch + PyBind11` ç¼–å†™ C++ æ¥å£
<!-- - âœ… ä½¿ç”¨ `torch.utils.cpp_extension` æ›¿ä»£ CMakeï¼Œç®€åŒ–æ„å»º -->
- âœ… åŒ…å«æµ‹è¯•ä¸æ€§èƒ½åŸºå‡†è„šæœ¬

---

## ğŸ“ é¡¹ç›®ç»“æ„

```bash
cuda-ops-template/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ kernels/              # CUDA kernel å®ç°ï¼ˆ.cu æ–‡ä»¶ï¼‰
â”‚   â”‚   â””â”€â”€ matmul.cu           # ç¤ºä¾‹ï¼šçŸ©é˜µä¹˜æ³• kernel
â”‚   â”œâ”€â”€ bindings/             # C++ ç»‘å®šå±‚ï¼ˆ.cpp æ–‡ä»¶ï¼‰
â”‚   â”‚   â””â”€â”€ matmul.cpp          # ç¤ºä¾‹ï¼šPyBind11 æ¥å£
â”‚   â””â”€â”€ utils/                # é€šç”¨å¤´æ–‡ä»¶
â”‚       â”œâ”€â”€ common.h          # CHECK_CUDA, CHECK_CONTIGUOUS ç­‰å®
â”œâ”€â”€ tests/                    # å•å…ƒæµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ test_matmul.py
â”œâ”€â”€ benchmarks/               # æ€§èƒ½æµ‹è¯•è„šæœ¬
â”‚   â””â”€â”€ benchmark_matmul.py
â”œâ”€â”€ compile_dev.py            # å¼€å‘æ¨¡å¼ï¼šå³æ—¶ç¼–è¯‘ + è‡ªåŠ¨åŠ è½½
â”œâ”€â”€ setup.py                  # å‘å¸ƒæ¨¡å¼ï¼šæ”¯æŒ pip install
â”œâ”€â”€ pyproject.toml            # Python åŒ…å…ƒæ•°æ®ï¼ˆå¯é€‰ï¼‰
â””â”€â”€ README.md                 # æœ¬æ–‡ä»¶
```

### ç‰¹ç‚¹

csrc ç°ä»£ C++ é£æ ¼ tests

TODO: libtorch + pybind11 å°è£… Python API


### ç®—å­

Elemwise:
- Add
Reduce:

Matmul:


---

## TODO: âš™ï¸ ç¼–è¯‘ä¸ä½¿ç”¨æ–¹å¼

### Make

### å¼€å‘æ¨¡å¼ï¼šå³æ—¶ç¼–è¯‘ï¼ˆæ¨èç”¨äºå¼€å‘è°ƒè¯•ï¼‰

æ— éœ€å®‰è£…ï¼Œä¿®æ”¹ä»£ç åé‡æ–°è¿è¡Œè‡ªåŠ¨é‡æ–°ç¼–è¯‘ã€‚

```bash
# å®‰è£…ä¾èµ–ï¼ˆé¦–æ¬¡ï¼‰
pip install torch>=2.0 pybind11

# è¿è¡Œç¼–è¯‘è„šæœ¬ï¼ˆè‡ªåŠ¨å‘ç°æ‰€æœ‰ç®—å­ï¼‰
python compile_dev.py
```

è¿è¡Œåä¼šè¾“å‡ºï¼š
```
ğŸ” å‘ç°ç®—å­: matmul -> ['src/bindings/matmul.cpp', 'src/kernels/matmul.cu']
âœ… matmul ç¼–è¯‘æˆåŠŸ
å¯ç”¨ç®—å­: ['matmul']
```

#### åœ¨ Python ä¸­ä½¿ç”¨ï¼š

```python
import torch
from compile_dev import cuda_ops  # åŠ¨æ€åŠ è½½çš„ç®—å­é›†åˆ

x = torch.randn(100, 200, device='cuda')
w = torch.randn(200, 300, device='cuda')

# è°ƒç”¨è‡ªå®šä¹‰ CUDA ç®—å­
y = cuda_ops['matmul'].matmul_forward(x, w)
print(y.shape)  # torch.Size([100, 300])
```

---

### 2. å‘å¸ƒæ¨¡å¼ï¼špip å®‰è£…ï¼ˆæ¨èç”¨äºæ¨¡å‹é›†æˆï¼‰

å°†ç®—å­ç¼–è¯‘ä¸º Python åŒ…ï¼Œæ”¯æŒ `import cuda_ops.xxx`ã€‚

```bash
# å®‰è£…ä¸ºå¯å¯¼å…¥çš„åŒ…ï¼ˆ-e è¡¨ç¤ºå¯ç¼–è¾‘æ¨¡å¼ï¼‰
pip install -e .
```

å®‰è£…æˆåŠŸåï¼Œåœ¨ä»»æ„ Python è„šæœ¬ä¸­ä½¿ç”¨ï¼š

```python
import torch
import cuda_ops.matmul

x = torch.randn(100, 200, device='cuda')
w = torch.randn(200, 300, device='cuda')

y = cuda_ops.matmul.matmul_forward(x, w)
```

> ğŸ’¡ é€‚ç”¨äºè®­ç»ƒè„šæœ¬ã€æ¨¡å‹éƒ¨ç½²ã€CI/CD æµç¨‹ã€‚

---

## âœ… æµ‹è¯•ç®—å­æ­£ç¡®æ€§

```bash
python tests/test_matmul.py
```

é¢„æœŸè¾“å‡ºï¼š
```
âœ… matmul æµ‹è¯•é€šè¿‡
```

---

## ğŸ“Š æ€§èƒ½åŸºå‡†æµ‹è¯•

```bash
python benchmarks/benchmark_matmul.py
```

é¢„æœŸè¾“å‡ºï¼š
```
ğŸš€ è‡ªå®šä¹‰ matmul è€—æ—¶: 1.2345 ms/æ¬¡
```

---

## â• å¦‚ä½•æ·»åŠ æ–°ç®—å­ï¼Ÿï¼ˆä¾‹å¦‚ `gelu` æˆ– `bitonic_sort`ï¼‰

åªéœ€ä¸¤æ­¥ï¼Œæ— éœ€ä¿®æ”¹ä»»ä½•æ„å»ºè„šæœ¬ï¼

### æ­¥éª¤ 1ï¼šåˆ›å»º CUDA Kernel
```bash
# ä¾‹å¦‚æ·»åŠ  GELU è¿‘ä¼¼è®¡ç®—
touch src/kernels/gelu.cu
```

### æ­¥éª¤ 2ï¼šåˆ›å»º C++ ç»‘å®š
```bash
touch src/bindings/gelu.cpp
```

> æ–‡ä»¶åå¿…é¡»ä¸€è‡´ï¼ˆå¦‚ `xxx.cu` + `xxx.cpp`ï¼‰

### æ­¥éª¤ 3ï¼šé‡æ–°ç¼–è¯‘
```bash
# å¼€å‘æ¨¡å¼
python compile_dev.py

# æˆ–å‘å¸ƒæ¨¡å¼
pip install -e .
```

å³å¯ä½¿ç”¨ï¼š
```python
# å¼€å‘æ¨¡å¼
y = cuda_ops['gelu'].gelu_forward(x)

# å‘å¸ƒæ¨¡å¼
import cuda_ops.gelu
y = cuda_ops.gelu.gelu_forward(x)
```

---

## Dependencies

- Python >= 3.8
- PyTorch >= 2.0ï¼ˆéœ€ CUDA ç‰ˆæœ¬åŒ¹é…ï¼‰
- CUDA Toolkitï¼ˆä¸ PyTorch ç‰ˆæœ¬å¯¹åº”ï¼‰
- `pybind11`ï¼ˆé€šå¸¸ç”± PyTorch è‡ªåŠ¨æä¾›ï¼‰


### Environment

It's recommended using `uv` to install dependencies.

```bash
# 1. åˆ›å»ºç¯å¢ƒ
uv venv Path-to-venv
source Path-to-venv/bin/activate

# 2. å®‰è£…ä¾èµ–
uv pip install -r requirements.txt

# 3. å®‰è£…ä½ çš„ CUDA æ‰©å±•
uv pip install -e .

# 4. éªŒè¯
python -c "
import torch
print('CUDA available:', torch.cuda.is_available())
print('CUDA version:', torch.version.cuda)
"
```

---

## ğŸ“š å‚è€ƒèµ„æ–™

- PyTorch CUDA Extensions: https://pytorch.org/docs/stable/cpp_extension.html
- PyBind11: https://pybind11.readthedocs.io/
- cuBLAS: https://docs.nvidia.com/cuda/cublas/

